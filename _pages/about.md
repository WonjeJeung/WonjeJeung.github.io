---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
  /* 필요한 다른 CSS 스타일이 있다면 여기에 추가하세요 */

  .blue-text {
    color: #007bff; /* 원하는 파란색 Hex Code로 변경 가능 */
  }
</style>

👋 Hello! I'm <span class="blue-text">Wonje Jeung</span>, a first-year Master's student in <span class="blue-text">Artificial Intelligence</span> at <span class="blue-text">Yonsei University</span>, where I am fortunate to be advised by Professor <span class="blue-text">Albert No</span>.
Previously, I gained valuable research experience working with Professor <span class="blue-text">Jonghyun Choi</span> at both Yonsei University and Seoul National University. I work on <span class="blue-text">privacy, safety, and reasoning and efficient model architectures</span>. 🤝 If these interests resonate with you, feel free to reach out—I'm always open to collaboration!

<hr>
<h2>News</h2>
<ul>
  <li><b>May 2025:</b> Four new papers are now on arXiv! These include work on safety alignment in reasoning models (<span>SAFEPATH</span>), unlearning benchmarks (<span>DUSK</span> and <span>R-TOFU</span>), and unlearning fragility (<span>SEPS</span>).</li>
  <li><b>May 2025:</b> Two papers—<span class="blue-text">LTF-TEST</span> and <span class="blue-text">RepBend</span>—have been accepted to ACL 2025. See you in Austria 🇦🇹!</li>
  <li><b>Dec 2024:</b> Our paper on sample-based privacy auditing for final model-only scenarios will appear at the NeurIPS SoLaR Workshop. See you in Canada 🇨🇦!</li>
  <li><b>July 2024:</b> One paper accepted to ECCV: <span class="blue-text">REALFRED</span>.</li>
  <li><b>May 2024:</b> We introduce a new information-theoretic metric for evaluating unlearning.</li>
  <li><b>March 2024:</b> One paper accepted to CVPR: <span class="blue-text">EARL</span>.</li>
</ul>
