---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
  /* í•„ìš”í•œ ë‹¤ë¥¸ CSS ìŠ¤íƒ€ì¼ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš” */

  .blue-text {
    color: #007bff; /* ì›í•˜ëŠ” íŒŒë€ìƒ‰ Hex Codeë¡œ ë³€ê²½ ê°€ëŠ¥ */
  }
</style>

ğŸ‘‹ Hello! I'm <span class="blue-text">Wonje Jeung</span>, a first-year Master's student in <span class="blue-text">Artificial Intelligence</span> at <span class="blue-text">Yonsei University</span>, where I am fortunate to be advised by Professor <span class="blue-text">Albert No</span>.
Previously, I gained valuable research experience working with Professor <span class="blue-text">Jonghyun Choi</span> at both Yonsei University and Seoul National University. I work on <span class="blue-text">privacy, safety, and reasoning and efficient model architectures</span>. ğŸ¤ If these interests resonate with you, feel free to reach outâ€”I'm always open to collaboration!

<hr>
<h2>News</h2>
<ul>
  <li><b>May 2025:</b> Four new papers are now on arXiv! These include work on safety alignment in reasoning models (<span>SAFEPATH</span>), unlearning benchmarks (<span>DUSK</span> and <span>R-TOFU</span>), and unlearning fragility (<span>SEPS</span>).</li>
  <li><b>May 2025:</b> Two papersâ€”<span class="blue-text">LTF-TEST</span> and <span class="blue-text">RepBend</span>â€”have been accepted to ACL 2025. See you in Austria ğŸ‡¦ğŸ‡¹!</li>
  <li><b>Dec 2024:</b> Our paper on sample-based privacy auditing for final model-only scenarios will appear at the NeurIPS SoLaR Workshop. See you in Canada ğŸ‡¨ğŸ‡¦!</li>
  <li><b>July 2024:</b> One paper accepted to ECCV: <span class="blue-text">REALFRED</span>.</li>
  <li><b>May 2024:</b> We introduce a new information-theoretic metric for evaluating unlearning.</li>
  <li><b>March 2024:</b> One paper accepted to CVPR: <span class="blue-text">EARL</span>.</li>
</ul>
